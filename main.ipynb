{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'plot_training_metrics' from 'scripts.classification' (c:\\Users\\will\\iCloudDrive\\Documents\\U-M\\lhs_712\\SMM4H\\scripts\\classification.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[58], line 12\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscipy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mspecial\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m softmax\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m main \u001b[38;5;28;01mas\u001b[39;00m classification_main\n\u001b[1;32m---> 12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mscripts\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mclassification\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m plot_training_metrics\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'plot_training_metrics' from 'scripts.classification' (c:\\Users\\will\\iCloudDrive\\Documents\\U-M\\lhs_712\\SMM4H\\scripts\\classification.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import scripts.data_cleaning\n",
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "from scipy.special import softmax\n",
    "from scripts.classification import main as classification_main\n",
    "from scripts.classification import plot_training_metrics\n",
    "import torch\n",
    "from transformers import AutoModelForSequenceClassification, AutoTokenizer, TrainingArguments\n",
    "from peft import PeftModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data shape: (2521, 3)\n",
      "Validation data shape: (786, 3)\n",
      "Test data shape: (8113, 2)\n",
      "Processed data saved to processed_train.csv\n",
      "Processed data saved to processed_valid.csv\n",
      "Processed data saved to processed_test.csv\n",
      "\n",
      "Example of original vs cleaned text:\n",
      "Original: Shingles Vaccine: Warning, this post contains an optimistic antidote to post-vax sickness! I survive...\n",
      "Cleaned: Warning, this post contains an optimistic antidote to post-vax sickness! I survived the shingles vac...\n",
      "\n",
      "Posts with title/comment structure (contains colon):\n",
      "Training: 2172 out of 2521 (86.2%)\n",
      "Validation: 662 out of 786 (84.2%)\n"
     ]
    }
   ],
   "source": [
    "scripts.data_cleaning.main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "labels\n",
       "0    1372\n",
       "1    1149\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"processed_train.csv\")\n",
    "train_df.labels.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data...\n",
      "Initializing model and tokenizer...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at cardiffnlp/twitter-roberta-large-2022-154m and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing datasets...\n",
      "Converting DataFrame to Dataset...\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29bee11ea92c4efea548c3b47574a1c6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/2521 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting DataFrame to Dataset...\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db109644d4624b3d8b93adaecf986e71",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/786 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up training arguments...\n",
      "Initializing trainer...\n",
      "Starting training...\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='212' max='212' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [212/212 04:12, Epoch 4/4]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       " <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>F1 Macro</th>\n",
       "      <th>F1 Negative</th>\n",
       "      <th>F1 Positive</th>\n",
       "      <th>Precision Macro</th>\n",
       "      <th>Precision Negative</th>\n",
       "      <th>Precision Positive</th>\n",
       "      <th>Recall Macro</th>\n",
       "      <th>Recall Negative</th>\n",
       "      <th>Recall Positive</th>\n",
       "      <th>Support Negative</th>\n",
       "      <th>Support Positive</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>No log</td>\n",
       "      <td>0.665261</td>\n",
       "      <td>0.806616</td>\n",
       "      <td>0.805405</td>\n",
       "      <td>0.820755</td>\n",
       "      <td>0.790055</td>\n",
       "      <td>0.805983</td>\n",
       "      <td>0.813084</td>\n",
       "      <td>0.798883</td>\n",
       "      <td>0.804996</td>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.781421</td>\n",
       "      <td>420</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>30</td>\n",
       "      <td>0.615500</td>\n",
       "      <td>0.441523</td>\n",
       "      <td>0.890585</td>\n",
       "      <td>0.890585</td>\n",
       "      <td>0.890306</td>\n",
       "      <td>0.890863</td>\n",
       "      <td>0.895272</td>\n",
       "      <td>0.958791</td>\n",
       "      <td>0.831754</td>\n",
       "      <td>0.894984</td>\n",
       "      <td>0.830952</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>420</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>45</td>\n",
       "      <td>0.615500</td>\n",
       "      <td>0.385196</td>\n",
       "      <td>0.918575</td>\n",
       "      <td>0.918549</td>\n",
       "      <td>0.920000</td>\n",
       "      <td>0.917098</td>\n",
       "      <td>0.920171</td>\n",
       "      <td>0.968421</td>\n",
       "      <td>0.871921</td>\n",
       "      <td>0.921702</td>\n",
       "      <td>0.876190</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>420</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>60</td>\n",
       "      <td>0.376800</td>\n",
       "      <td>0.517775</td>\n",
       "      <td>0.853690</td>\n",
       "      <td>0.852970</td>\n",
       "      <td>0.842681</td>\n",
       "      <td>0.863258</td>\n",
       "      <td>0.877282</td>\n",
       "      <td>0.990354</td>\n",
       "      <td>0.764211</td>\n",
       "      <td>0.862568</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>0.991803</td>\n",
       "      <td>420</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75</td>\n",
       "      <td>0.376800</td>\n",
       "      <td>0.378131</td>\n",
       "      <td>0.940204</td>\n",
       "      <td>0.940085</td>\n",
       "      <td>0.942753</td>\n",
       "      <td>0.937417</td>\n",
       "      <td>0.939686</td>\n",
       "      <td>0.965087</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.941589</td>\n",
       "      <td>0.921429</td>\n",
       "      <td>0.961749</td>\n",
       "      <td>420</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>90</td>\n",
       "      <td>0.341800</td>\n",
       "      <td>0.346231</td>\n",
       "      <td>0.950382</td>\n",
       "      <td>0.950155</td>\n",
       "      <td>0.953516</td>\n",
       "      <td>0.946794</td>\n",
       "      <td>0.950079</td>\n",
       "      <td>0.954654</td>\n",
       "      <td>0.945504</td>\n",
       "      <td>0.950234</td>\n",
       "      <td>0.952381</td>\n",
       "      <td>0.948087</td>\n",
       "      <td>420</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>105</td>\n",
       "      <td>0.341800</td>\n",
       "      <td>0.360342</td>\n",
       "      <td>0.938931</td>\n",
       "      <td>0.938842</td>\n",
       "      <td>0.941176</td>\n",
       "      <td>0.936508</td>\n",
       "      <td>0.938695</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.940749</td>\n",
       "      <td>0.914286</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>420</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>120</td>\n",
       "      <td>0.325100</td>\n",
       "      <td>0.376265</td>\n",
       "      <td>0.933842</td>\n",
       "      <td>0.933746</td>\n",
       "      <td>0.936275</td>\n",
       "      <td>0.931217</td>\n",
       "      <td>0.933605</td>\n",
       "      <td>0.964646</td>\n",
       "      <td>0.902564</td>\n",
       "      <td>0.935636</td>\n",
       "      <td>0.909524</td>\n",
       "      <td>0.961749</td>\n",
       "      <td>420</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>135</td>\n",
       "      <td>0.325100</td>\n",
       "      <td>0.363756</td>\n",
       "      <td>0.940204</td>\n",
       "      <td>0.940056</td>\n",
       "      <td>0.943030</td>\n",
       "      <td>0.937082</td>\n",
       "      <td>0.939564</td>\n",
       "      <td>0.960494</td>\n",
       "      <td>0.918635</td>\n",
       "      <td>0.941237</td>\n",
       "      <td>0.926190</td>\n",
       "      <td>0.956284</td>\n",
       "      <td>420</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.297400</td>\n",
       "      <td>0.355654</td>\n",
       "      <td>0.954198</td>\n",
       "      <td>0.953853</td>\n",
       "      <td>0.957845</td>\n",
       "      <td>0.949861</td>\n",
       "      <td>0.955573</td>\n",
       "      <td>0.942396</td>\n",
       "      <td>0.968750</td>\n",
       "      <td>0.952752</td>\n",
       "      <td>0.973810</td>\n",
       "      <td>0.931694</td>\n",
       "      <td>420</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>165</td>\n",
       "      <td>0.297400</td>\n",
       "      <td>0.364263</td>\n",
       "      <td>0.944020</td>\n",
       "      <td>0.943875</td>\n",
       "      <td>0.946731</td>\n",
       "      <td>0.941019</td>\n",
       "      <td>0.943369</td>\n",
       "      <td>0.963054</td>\n",
       "      <td>0.923684</td>\n",
       "      <td>0.944984</td>\n",
       "      <td>0.930952</td>\n",
       "      <td>0.959016</td>\n",
       "      <td>420</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>180</td>\n",
       "      <td>0.291800</td>\n",
       "      <td>0.359837</td>\n",
       "      <td>0.949109</td>\n",
       "      <td>0.948903</td>\n",
       "      <td>0.952153</td>\n",
       "      <td>0.945652</td>\n",
       "      <td>0.948636</td>\n",
       "      <td>0.956731</td>\n",
       "      <td>0.940541</td>\n",
       "      <td>0.949219</td>\n",
       "      <td>0.947619</td>\n",
       "      <td>0.950820</td>\n",
       "      <td>420</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>195</td>\n",
       "      <td>0.291800</td>\n",
       "      <td>0.356276</td>\n",
       "      <td>0.949109</td>\n",
       "      <td>0.948886</td>\n",
       "      <td>0.952267</td>\n",
       "      <td>0.945504</td>\n",
       "      <td>0.948740</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.942935</td>\n",
       "      <td>0.949044</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.948087</td>\n",
       "      <td>420</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>210</td>\n",
       "      <td>0.285800</td>\n",
       "      <td>0.354190</td>\n",
       "      <td>0.949109</td>\n",
       "      <td>0.948886</td>\n",
       "      <td>0.952267</td>\n",
       "      <td>0.945504</td>\n",
       "      <td>0.948740</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.942935</td>\n",
       "      <td>0.949044</td>\n",
       "      <td>0.950000</td>\n",
       "      <td>0.948087</td>\n",
       "      <td>420</td>\n",
       "      <td>366</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting training metrics...\n",
      "Training metrics plot saved as training_metrics.png\n",
      "Saving model and tokenizer...\n",
      "Saving model to temporary directory: C:\\Users\\will\\AppData\\Local\\Temp\\tmp7yx_p42t\n",
      "Model successfully saved to ./final_model\n",
      "Evaluating on training set...\n"
     ]
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Results: {'eval_loss': 0.28857025504112244, 'eval_accuracy': 0.989289964299881, 'eval_f1_macro': 0.9892000702573771, 'eval_f1_negative': 0.990185387131952, 'eval_f1_positive': 0.9882147533828023, 'eval_precision_macro': 0.9894578294126686, 'eval_precision_negative': 0.9876722262509064, 'eval_precision_positive': 0.9912434325744308, 'eval_recall_macro': 0.9889579479684452, 'eval_recall_negative': 0.9927113702623906, 'eval_recall_positive': 0.9852045256744996, 'eval_support_negative': 1372, 'eval_support_positive': 1149, 'eval_runtime': 19.693, 'eval_samples_per_second': 128.015, 'eval_steps_per_second': 5.383, 'epoch': 4.0}\n",
      "Evaluating on validation set...\n",
      "Validation Results: {'eval_loss': 0.3556537926197052, 'eval_accuracy': 0.9541984732824428, 'eval_f1_macro': 0.9538530787446262, 'eval_f1_negative': 0.9578454332552693, 'eval_f1_positive': 0.9498607242339833, 'eval_precision_macro': 0.9555731566820276, 'eval_precision_negative': 0.9423963133640553, 'eval_precision_positive': 0.96875, 'eval_recall_macro': 0.952751756440281, 'eval_recall_negative': 0.9738095238095238, 'eval_recall_positive': 0.9316939890710383, 'eval_support_negative': 420, 'eval_support_positive': 366, 'eval_runtime': 6.141, 'eval_samples_per_second': 127.992, 'eval_steps_per_second': 5.374, 'epoch': 4.0}\n",
      "Generating validation predictions...\n",
      "Validation predictions saved to validation_predictions.csv\n",
      "Generating predictions...\n",
      "Generating predictions...\n",
      "Converting DataFrame to Dataset...\n",
      "Tokenizing dataset...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a726eca48246cc99a1994209338abf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map:   0%|          | 0/8113 [00:00<?, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictions saved to prediction_task6.csv\n"
     ]
    }
   ],
   "source": [
    "classification_main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.51.1\n"
     ]
    }
   ],
   "source": [
    "import transformers\n",
    "print(transformers.__version__)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
